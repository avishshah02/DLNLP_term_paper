{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLUZHZKkM6S7",
        "outputId": "af1d069f-eb80-4be5-c267-9be1c2346ab3"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: huggingface-hub==0.0.2 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (3.7.0)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n",
            "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from datasets) (0.8.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.2->datasets) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q56PwL1LiG3N",
        "outputId": "70fb2d8e-22fe-4af2-d312-f3c68b913523"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "\n",
        "import json\n",
        "import sys\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "import collections\n",
        "from pathlib import Path\n",
        "\n",
        "import transformers\n",
        "import datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gENJjhhcs768"
      },
      "source": [
        "def fix_random(seed: int) -> None:\n",
        "    \"\"\"Fix all the possible sources of randomness.\n",
        "\n",
        "    Args:\n",
        "        seed: the seed to use.\n",
        "    \"\"\"\n",
        "\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9uG9WFsN6-S"
      },
      "source": [
        "fix_random(seed=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ib8_3-Scxvk8"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIGqe1a6rceN"
      },
      "source": [
        "class LoadData():\n",
        "    def __init__(self,\n",
        "                 path_to_json_file: str,\n",
        "                 checkpoint_path: str,\n",
        "                 train_file: str = 'train.json',\n",
        "                 val_file: str = 'val.json') -> None:\n",
        "        \"\"\"Load the data by flattening the json file and saving it.\n",
        "\n",
        "        Args:\n",
        "            path_to_json_file: path to the json file.\n",
        "            checkpoint_path: path where to save the json files.\n",
        "            train_file: name of the train json file that will be created.\n",
        "            val_file: name of the val json file that will be created.\n",
        "        \"\"\"\n",
        "\n",
        "        self.path_to_json_file = path_to_json_file\n",
        "        self.checkpoint_path = checkpoint_path\n",
        "\n",
        "        self.train_file = train_file\n",
        "        self.val_file = val_file\n",
        "\n",
        "        self.data = self.load_data()\n",
        "\n",
        "    def load_data(self):\n",
        "        with open(self.path_to_json_file, 'r') as f:\n",
        "            train_data = json.load(f)\n",
        "        print(f'Flattening SQUAD {train_data[\"version\"]}')\n",
        "        train_data_flat, val_data_flat, errors = self.load_squad_data(train_data)\n",
        "        print(f'\\nErroneous Datapoints: {errors}')\n",
        "\n",
        "        with open(Path(self.checkpoint_path) / Path(self.train_file), 'w') as file:\n",
        "            train_data = {'data':train_data_flat}\n",
        "            file.write(json.dumps(train_data))\n",
        "            file.close()\n",
        "\n",
        "        with open(Path(self.checkpoint_path) / Path(self.val_file), 'w') as file:\n",
        "            val_data = {'data':val_data_flat}\n",
        "            file.write(json.dumps(val_data))\n",
        "            file.close()\n",
        "\n",
        "    def load_squad_data(self, data, split=0.2):\n",
        "\n",
        "        errors = 0\n",
        "        flattened_data_train = []\n",
        "        flattened_data_val = []\n",
        "\n",
        "        train_range = len(data['data']) - (len(data['data']) * split)\n",
        "\n",
        "        for i, article in enumerate(data[\"data\"]):\n",
        "            title = article.get(\"title\", \"\").strip()\n",
        "            for paragraph in article[\"paragraphs\"]:\n",
        "                context = paragraph[\"context\"].strip()\n",
        "                for qa in paragraph[\"qas\"]:\n",
        "                    question = qa[\"question\"].strip()\n",
        "                    id_ = qa[\"id\"]\n",
        "\n",
        "                    answer_starts = [answer[\"answer_start\"] for answer in qa[\"answers\"]]\n",
        "                    answers = [answer[\"text\"].strip() for answer in qa[\"answers\"]]\n",
        "\n",
        "                    # Features currently used are \"context\", \"question\", and \"answers\".\n",
        "                    # Others are extracted here for the ease of future expansions.\n",
        "                    if i <= train_range:\n",
        "                        flattened_data_train.append({\"title\": title,\n",
        "                                                     \"context\": context,\n",
        "                                                     \"question\": question,\n",
        "                                                     \"id\": id_,\n",
        "                                                     \"answers\": {\n",
        "                                                         \"answer_start\": answer_starts,\n",
        "                                                         \"text\": answers}\n",
        "                                                     })\n",
        "                    else:\n",
        "                        flattened_data_val.append({\"title\": title,\n",
        "                                                   \"context\": context,\n",
        "                                                   \"question\": question,\n",
        "                                                   \"id\": id_,\n",
        "                                                   \"answers\": {\n",
        "                                                       \"answer_start\": answer_starts,\n",
        "                                                       \"text\": answers}\n",
        "                                                   })\n",
        "\n",
        "        return flattened_data_train, flattened_data_val, errors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "f161c957bbea4de2b96e550288aa79b7",
            "0ee45de9240c4cda80fb7301a2d94e7c",
            "44f0bf1ea8054c40a24b446359b6e2f7",
            "e6ad3316b26e4f4680583b8ae38c6d8c",
            "f609f63e272f44819c6c3922f9e57e71",
            "9ec4310884834518baf1737fb46d1bba",
            "5082763de3024af4aa1d14be2bb669a8",
            "c18ecd5ad9364562a73146c2e2dd63e0",
            "fdc29d23be32451b838228b61360bdb0",
            "be03f3789aff4494a7f34cb8088a1f81",
            "4da4295d7d2242149f58c0a5ff29c18a",
            "c791141229bc4a04bebfc48927490b68",
            "a38bfbc9a8fd46508883fad134d1c1a5",
            "139aaf524c574274aae8feada1e94685",
            "8296e686054a4dcb94171f9cef5817d0",
            "d217fd56c7114c5f92c9e2fd335a2344"
          ]
        },
        "id": "Ji9Vo1imO5Vq",
        "outputId": "050944fc-ff9e-4306-c9ce-66d932f7d708"
      },
      "source": [
        "from datasets import load_dataset\n",
        "train_data = load_dataset('json', data_files=data_path+\"train.json\", field='data')\n",
        "val_data = load_dataset('json', data_files=data_path+\"val.json\", field='data')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using custom data configuration default-8f4de82f4daa2955\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/json/default-8f4de82f4daa2955/0.0.0/dc7ee63ec8b554c48ecc5a8a6fbe27af8071408c244e4347cf9222d6206d83a2...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f161c957bbea4de2b96e550288aa79b7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rDataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-8f4de82f4daa2955/0.0.0/dc7ee63ec8b554c48ecc5a8a6fbe27af8071408c244e4347cf9222d6206d83a2. Subsequent calls will reuse this data.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using custom data configuration default-9129e4e01f74642c\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/json/default-9129e4e01f74642c/0.0.0/dc7ee63ec8b554c48ecc5a8a6fbe27af8071408c244e4347cf9222d6206d83a2...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fdc29d23be32451b838228b61360bdb0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rDataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-9129e4e01f74642c/0.0.0/dc7ee63ec8b554c48ecc5a8a6fbe27af8071408c244e4347cf9222d6206d83a2. Subsequent calls will reuse this data.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670
        },
        "id": "b6twxoFaRNHK",
        "outputId": "53669bef-dc31-407f-ae94-9609aee5ee3b"
      },
      "source": [
        "def get_text(answer: list) -> str:\n",
        "    \"\"\"Extract only the text from the answers.text column\n",
        "\n",
        "    Args:\n",
        "        answer: the answer.\n",
        "    \"\"\"\n",
        "    return answer[0]\n",
        "\n",
        "def get_json_data(json_path: str) -> dict:\n",
        "    \"\"\"Get the json data in form of a dictionary\n",
        "\n",
        "    Args:\n",
        "        json_path: path to the json file.\n",
        "    \"\"\"\n",
        "    # Opening JSON file\n",
        "    f = open(json_path)\n",
        "    # returns JSON object as a dictionary\n",
        "    json_data = json.load(f)\n",
        "    # Closing file\n",
        "    f.close()\n",
        "    return json_data\n",
        "\n",
        "train_dataframe = pd.json_normalize(get_json_data(data_path+\"train.json\"), record_path='data')\n",
        "train_dataframe[\"answers.text\"] = train_dataframe[\"answers.text\"].apply(get_text)\n",
        "\n",
        "\n",
        "val_dataframe = pd.json_normalize(get_json_data(data_path+\"val.json\"), record_path='data')\n",
        "val_dataframe[\"answers.text\"] = val_dataframe[\"answers.text\"].apply(get_text)\n",
        "\n",
        "train_dataframe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>id</th>\n",
              "      <th>answers.answer_start</th>\n",
              "      <th>answers.text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
              "      <td>5733be284776f41900661182</td>\n",
              "      <td>[515]</td>\n",
              "      <td>Saint Bernadette Soubirous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>What is in front of the Notre Dame Main Building?</td>\n",
              "      <td>5733be284776f4190066117f</td>\n",
              "      <td>[188]</td>\n",
              "      <td>a copper statue of Christ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
              "      <td>5733be284776f41900661180</td>\n",
              "      <td>[279]</td>\n",
              "      <td>the Main Building</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>What is the Grotto at Notre Dame?</td>\n",
              "      <td>5733be284776f41900661181</td>\n",
              "      <td>[381]</td>\n",
              "      <td>a Marian place of prayer and reflection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>University_of_Notre_Dame</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>What sits on top of the Main Building at Notre...</td>\n",
              "      <td>5733be284776f4190066117e</td>\n",
              "      <td>[92]</td>\n",
              "      <td>a golden statue of the Virgin Mary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69387</th>\n",
              "      <td>Empiricism</td>\n",
              "      <td>John Dewey (1859–1952) modified James' pragmat...</td>\n",
              "      <td>Who came up with 'instrumentalism'?</td>\n",
              "      <td>572b459134ae481900dead71</td>\n",
              "      <td>[0]</td>\n",
              "      <td>John Dewey</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69388</th>\n",
              "      <td>Empiricism</td>\n",
              "      <td>John Dewey (1859–1952) modified James' pragmat...</td>\n",
              "      <td>What did Dewey think about reality?</td>\n",
              "      <td>572b459134ae481900dead72</td>\n",
              "      <td>[317]</td>\n",
              "      <td>reality is determined by past experience</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69389</th>\n",
              "      <td>Empiricism</td>\n",
              "      <td>John Dewey (1859–1952) modified James' pragmat...</td>\n",
              "      <td>When was Dewey born?</td>\n",
              "      <td>572b459134ae481900dead73</td>\n",
              "      <td>[12]</td>\n",
              "      <td>1859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69390</th>\n",
              "      <td>Empiricism</td>\n",
              "      <td>John Dewey (1859–1952) modified James' pragmat...</td>\n",
              "      <td>When did Dewey die?</td>\n",
              "      <td>572b459134ae481900dead74</td>\n",
              "      <td>[17]</td>\n",
              "      <td>1952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69391</th>\n",
              "      <td>Empiricism</td>\n",
              "      <td>John Dewey (1859–1952) modified James' pragmat...</td>\n",
              "      <td>What was instrumentalism a modification of?</td>\n",
              "      <td>572b459134ae481900dead75</td>\n",
              "      <td>[32]</td>\n",
              "      <td>James' pragmatism</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>69392 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                          title  ...                              answers.text\n",
              "0      University_of_Notre_Dame  ...                Saint Bernadette Soubirous\n",
              "1      University_of_Notre_Dame  ...                 a copper statue of Christ\n",
              "2      University_of_Notre_Dame  ...                         the Main Building\n",
              "3      University_of_Notre_Dame  ...   a Marian place of prayer and reflection\n",
              "4      University_of_Notre_Dame  ...        a golden statue of the Virgin Mary\n",
              "...                         ...  ...                                       ...\n",
              "69387                Empiricism  ...                                John Dewey\n",
              "69388                Empiricism  ...  reality is determined by past experience\n",
              "69389                Empiricism  ...                                      1859\n",
              "69390                Empiricism  ...                                      1952\n",
              "69391                Empiricism  ...                         James' pragmatism\n",
              "\n",
              "[69392 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "uvVkdnU17gEt",
        "outputId": "25ca3d9b-c1ad-4a3a-b4ea-54bf4558726a"
      },
      "source": [
        "figsize = (10,6)\n",
        "train_dataframe['context'].apply(len).plot.hist(title=\"Contex length histogram\", bins=20, figsize=figsize, grid=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fdb9b5dca90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "Jab-fQ1X8dfY",
        "outputId": "85c83b7e-bf0f-4a6d-b800-c624946fcfa3"
      },
      "source": [
        "train_dataframe['question'].apply(len).plot.hist(title=\"Question length histogram\", bins=20, figsize=figsize, grid=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fdb89259b90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "lY9PhtcW8pmt",
        "outputId": "b4e4624e-d096-4909-c4d9-c02dbbf61f85"
      },
      "source": [
        "train_dataframe['answers.text'].apply(len).plot.hist(title=\"Answer length histogram\", bins=20, figsize=figsize, grid=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fdb89d92090>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAngAAAF1CAYAAAB74Zd5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfbRddX3n8fdHIoooAmIjBWpQUy2WihiBqbbe6ggBRoOttThUgmWMswozdZp2jC47WJEZnBmlpaNWrChYFfGBihJFpB7UaXlUBIEyRAwlkQflQYhYMPidP87vtof03uSSe8+99+z7fq111t37t59++3w58ePe+3dOqgpJkiR1x2PmugOSJEmaWQY8SZKkjjHgSZIkdYwBT5IkqWMMeJIkSR1jwJMkSeoYA56kzkry9iR/PUfH7iX5D1NcdyzJhq0s/8skfzJzvZPUdQY8SdvUwso9SR43132Zj4YdJKvqP1bVyVPox/ok/3ZY/ZA0Ogx4krYqyRLg14ACXjmnndmKJIvmug9d5vsrjRYDnqRtORa4FPgIsHJwQZKPJHlvkguS3J/ksiTPbMuS5LQkdya5L8m1SX45yb5J7k3ymLbeB5PcObDPjyZ5U5t+cpIPJbktycYk70yyQ1t2XJL/245xF/D2bZ1IkkOS/F07/reTjA0s6yU5ue3z/iRfTrLHwPJjk9yS5K4kfzJ+tSzJcuCtwO8k2ZTk2wOHfPpk+5ukf6vb+3Vbktdv8T6/s03vkeQL7RzuTvL1JI9J8lHgF4DPt37817b+K5Nc19bvJfmlgf0emORbrX+fSvLJgeOMJdmQ5M1Jbgc+nGS3duwftCu6X0iy9xbv4Tvbe7wpyeeTPCXJx9p/A1e0/8MgacgMeJK25VjgY+11WJLFWyw/GvhTYDdgHXBKaz8U+HXgF4EnA68B7qqq7wH3Ac9v6/06sGkgeLwEuKRNfwTYDDyrrX8oMPhc28HAzcDigeNOKMlewAXAO4HdgT8CPpPkqQOr/Xvg9cDPATu2dUiyH/A+4Bhgz3Y+ewFU1ZeA/w58sqqeWFXP29b+JvG0gf0eD7w3yW4TrLca2AA8tZ33W/vdqNcB/wi8ovXjfyb5ReATwJva+mvpB8Adk+wInEf/Pd69rfeqCfq0O/B0YBX9/834cJv/BeAnwP/ZYpujgde183gm8Pdtm92BG4CTtvIeSJohBjxJk0ryYvr/Y35uVV0FfJd+aBl0XlVdXlWb6YfAA1r7T4EnAc8BUlU3VNVtbdklwEuSPK3Nf7rN7wvsAny7BckjgDdV1Y+r6k7gNPoBYtz3q+ovqmpzVf1kG6fzu8DaqlpbVT+rqouAK9sxxn24qv5f29e5A+fyauDzVfWNqnoI+G/0b1lvy2T7m8hPgXdU1U+rai2wCXj2JOvtCTy9rfv1mvxHxX8HuKCqLqqqnwL/G9gJ+FXgEGARcHrbz2eBy7fY/mfASVX1YFX9pKruqqrPVNUDVXU//VD9kgnO+btV9SPgi8B3q+or7b+PT/EvwV7SEBnwJG3NSuDLVfXDNv9xtrhNC9w+MP0A8ESAqvpb+ld33gvcmeSMJLu09S4Bxuhfvfsa0KMfFF4CfL2qfkY/WD4WuK3dXrwX+AD9q2Hjbn0U5/J04LfH99X292L6YWmr5wL8/OCxquoB4K4pHHOy/U3krhaCtrX+/6J/pfTLSW5OsmYr+/x54Jbxmfa+3kr/6trPAxu3CIdbvp8/qKp/Gp9J8oQkH2i3qu+jX7tdx2+bN3cMTP9kgvmtvQeSZogBT9KEkuxE/7bqS5Lc3p7D+i/A85I8b+tb91XV6VX1AmA/+rdq/7gtuoT+wI2xNv0N4EU88vbsrcCDwB5VtWt77VJVzx08xKM4pVuBjw7sa9eq2rmqTp3CtrcBg8+a7QQ8ZTv7MS1VdX9Vra6qZ9Af9PKHSV42ST++Tz/YAv3nIoF9gI30z2mv1jZuny0Pt8X8avpXFQ+uql3oB3SAIGleMeBJmsxRwMP0w9kB7fVLwNfpP5e3VUlemOTgJI8Ffgz8E/1bflTVTfSv5vwucElV3Uf/Ss9v0QJeu537ZeDdSXZpAwmemWTLW4JT9dfAK5IclmSHJI9vAwn23uaW/VvIr0jyq+3ZtbfzyFBzB7AkbeDIMCX5d0me1YLZj+jX6GcD/XjGwOrnAkcmeVmrw2r6ofnv6D8b9zBwYpJFSVYAB23j8E+iX7d7k+yOz9NJ85YBT9JkVtJ/nuofq+r28Rf9267HZNtfm7EL8EHgHvq3Ce+if3tx3CX0b0veOjAf4JsD6xxLf3DC9W0/n+aRt1SnrB1nBf1BCT+gf0Xvj5nCv4NVdR3wn4Bz6F/52gTcST8sQf/ZMoC7knzzX+9hRi0FvtL68PfA+6rqq23Z/wDe1m5B/1FV3Ug/RP8F8EPgFfQHYTzUniX8TfoDOu5t631h4Jwm8mf0n+H7If2R1V+a6ZOTNDMy+bO5kqSJJHki/VC0tI0K7oQklwF/WVUfnuu+SJoer+BJ0hQkeUUbZLAz/dGo1wLr57ZX05PkJUme1m7RrgR+Ba/KSZ1gwJOkqVlBf9DC9+nfJj16K19PMiqeDXyb/tXI1cCrB77KRtII8xatJElSx3gFT5IkqWMMeJIkSR2zra856Jw99tijlixZMpR9//jHP2bnnXceyr41s6zVaLBOo8NajQbrNDrGa3XVVVf9sKqeuu0tHmnBBbwlS5Zw5ZVXDmXfvV6PsbGxoexbM8tajQbrNDqs1WiwTqNjvFZJbtn22v+at2glSZI6xoAnSZLUMQY8SZKkjjHgSZIkdYwBT5IkqWMMeJIkSR1jwJMkSeoYA54kSVLHGPAkSZI6xoAnSZLUMQY8SZKkjjHgSZIkdYwBT5IkqWMWzXUHumjJmguGfoz1px459GNIkqTR5BU8SZKkjjHgSZIkdYwBT5IkqWMMeJIkSR1jwJMkSeoYA54kSVLHGPAkSZI6xoAnSZLUMQY8SZKkjjHgSZIkdYwBT5IkqWMMeJIkSR1jwJMkSeoYA54kSVLHGPAkSZI6xoAnSZLUMQY8SZKkjhlawEvy+CSXJ/l2kuuS/Glr3zfJZUnWJflkkh1b++Pa/Lq2fMnAvt7S2m9McthA+/LWti7JmmGdiyRJ0igZ5hW8B4GXVtXzgAOA5UkOAd4FnFZVzwLuAY5v6x8P3NPaT2vrkWQ/4GjgucBy4H1JdkiyA/Be4HBgP+C1bV1JkqQFbWgBr/o2tdnHtlcBLwU+3drPAo5q0yvaPG35y5KktZ9TVQ9W1feAdcBB7bWuqm6uqoeAc9q6kiRJC9qiYe68XWW7CngW/att3wXurarNbZUNwF5tei/gVoCq2pzkR8BTWvulA7sd3ObWLdoPnqQfq4BVAIsXL6bX603rvCazadMmer0eq/ffvO2Vp2lY57BQjNdK85t1Gh3WajRYp9Ex3VoNNeBV1cPAAUl2Bc4DnjPM422lH2cAZwAsW7asxsbGhnKcXq/H2NgYx625YCj7H7T+mLGhH6PLxmul+c06jQ5rNRqs0+iYbq1mZRRtVd0LfBX4N8CuScaD5d7Axja9EdgHoC1/MnDXYPsW20zWLkmStKANcxTtU9uVO5LsBLwcuIF+0Ht1W20l8Lk2fX6bpy3/26qq1n50G2W7L7AUuBy4AljaRuXuSH8gxvnDOh9JkqRRMcxbtHsCZ7Xn8B4DnFtVX0hyPXBOkncC3wI+1Nb/EPDRJOuAu+kHNqrquiTnAtcDm4ET2q1fkpwIXAjsAJxZVdcN8XwkSZJGwtACXlVdAzx/gvab6Y+A3bL9n4DfnmRfpwCnTNC+Flg77c5KkiR1iL9kIUmS1DEGPEmSpI4x4EmSJHWMAU+SJKljDHiSJEkdY8CTJEnqGAOeJElSxxjwJEmSOsaAJ0mS1DEGPEmSpI4x4EmSJHWMAU+SJKljDHiSJEkdY8CTJEnqGAOeJElSxxjwJEmSOsaAJ0mS1DEGPEmSpI4x4EmSJHWMAU+SJKljDHiSJEkdY8CTJEnqGAOeJElSxxjwJEmSOsaAJ0mS1DEGPEmSpI4x4EmSJHWMAU+SJKljDHiSJEkdY8CTJEnqGAOeJElSxxjwJEmSOsaAJ0mS1DEGPEmSpI4x4EmSJHWMAU+SJKljDHiSJEkdY8CTJEnqGAOeJElSxwwt4CXZJ8lXk1yf5Lokf9Da355kY5Kr2+uIgW3ekmRdkhuTHDbQvry1rUuyZqB93ySXtfZPJtlxWOcjSZI0KoZ5BW8zsLqq9gMOAU5Isl9bdlpVHdBeawHasqOB5wLLgfcl2SHJDsB7gcOB/YDXDuznXW1fzwLuAY4f4vlIkiSNhKEFvKq6raq+2abvB24A9trKJiuAc6rqwar6HrAOOKi91lXVzVX1EHAOsCJJgJcCn27bnwUcNZyzkSRJGh2z8gxekiXA84HLWtOJSa5JcmaS3VrbXsCtA5ttaG2TtT8FuLeqNm/RLkmStKAtGvYBkjwR+Azwpqq6L8n7gZOBan/fDfzekPuwClgFsHjxYnq93lCOs2nTJnq9Hqv337ztladpWOewUIzXSvObdRod1mo0WKfRMd1aDTXgJXks/XD3sar6LEBV3TGw/IPAF9rsRmCfgc33bm1M0n4XsGuSRe0q3uD6j1BVZwBnACxbtqzGxsamd2KT6PV6jI2NcdyaC4ay/0Hrjxkb+jG6bLxWmt+s0+iwVqPBOo2O6dZqmKNoA3wIuKGq3jPQvufAaq8CvtOmzweOTvK4JPsCS4HLgSuApW3E7I70B2KcX1UFfBV4ddt+JfC5YZ2PJEnSqBjmFbwXAa8Drk1ydWt7K/1RsAfQv0W7HngjQFVdl+Rc4Hr6I3BPqKqHAZKcCFwI7ACcWVXXtf29GTgnyTuBb9EPlJIkSQva0AJeVX0DyASL1m5lm1OAUyZoXzvRdlV1M/1RtpIkSWr8JQtJkqSOMeBJkiR1jAFPkiSpYwx4kiRJHWPAkyRJ6hgDniRJUscY8CRJkjrGgCdJktQxBjxJkqSOMeBJkiR1jAFPkiSpYwx4kiRJHWPAkyRJ6hgDniRJUscY8CRJkjrGgCdJktQxBjxJkqSOMeBJkiR1jAFPkiSpYwx4kiRJHWPAkyRJ6hgDniRJUscY8CRJkjrGgCdJktQxBjxJkqSOMeBJkiR1jAFPkiSpYxbNdQe0fZasuWBWjrP+1CNn5TiSJGnmeAVPkiSpYwx4kiRJHWPAkyRJ6hgDniRJUscY8CRJkjrGgCdJktQxBjxJkqSOMeBJkiR1jAFPkiSpYwx4kiRJHWPAkyRJ6pihBbwk+yT5apLrk1yX5A9a++5JLkpyU/u7W2tPktOTrEtyTZIDB/a1sq1/U5KVA+0vSHJt2+b0JBnW+UiSJI2KYV7B2wysrqr9gEOAE5LsB6wBLq6qpcDFbR7gcGBpe60C3g/9QAicBBwMHAScNB4K2zpvGNhu+RDPR5IkaSQMLeBV1W1V9c02fT9wA7AXsAI4q612FnBUm14BnF19lwK7JtkTOAy4qKrurqp7gIuA5W3ZLlV1aVUVcPbAviRJkhasWXkGL8kS4PnAZcDiqrqtLbodWNym9wJuHdhsQ2vbWvuGCdolSZIWtEXDPkCSJwKfAd5UVfcNPiZXVZWkZqEPq+jf9mXx4sX0er2hHGfTpk30ej1W7795KPufC8N6r+baeK00v1mn0WGtRoN1Gh3TrdVQA16Sx9IPdx+rqs+25juS7FlVt7XbrHe29o3APgOb793aNgJjW7T3WvveE6z/r1TVGcAZAMuWLauxsbGJVpu2Xq/H2NgYx625YCj7nwvrjxmb6y4MxXitNL9Zp9FhrUaDdRod063VMEfRBvgQcENVvWdg0fnA+EjYlcDnBtqPbaNpDwF+1G7lXggcmmS3NrjiUODCtuy+JIe0Yx07sC9JkqQFa5hX8F4EvA64NsnVre2twKnAuUmOB24BXtOWrQWOANYBDwCvB6iqu5OcDFzR1ntHVd3dpn8f+AiwE/DF9pIkSVrQhhbwquobwGTfS/eyCdYv4IRJ9nUmcOYE7VcCvzyNbkqSJHWOv2QhSZLUMVMKeEn2H3ZHJEmSNDOmegXvfUkuT/L7SZ481B5JkiRpWqYU8Krq14Bj6H+NyVVJPp7k5UPtmSRJkrbLlJ/Bq6qbgLcBbwZeApye5B+S/OawOidJkqRHb6rP4P1KktPo/57sS4FXVNUvtenThtg/SZIkPUpT/ZqUvwD+CnhrVf1kvLGqvp/kbUPpmSRJkrbLVAPekcBPquphgCSPAR5fVQ9U1UeH1jtJkiQ9alN9Bu8r9H8tYtwTWpskSZLmmakGvMdX1abxmTb9hOF0SZIkSdMx1YD34yQHjs8keQHwk62sL0mSpDky1Wfw3gR8Ksn36f++7NOA3xlaryRJkrTdphTwquqKJM8Bnt2abqyqnw6vW5IkSdpeU72CB/BCYEnb5sAkVNXZQ+mVJEmSttuUAl6SjwLPBK4GHm7NBRjwJEmS5pmpXsFbBuxXVTXMzkiSJGn6pjqK9jv0B1ZIkiRpnpvqFbw9gOuTXA48ON5YVa8cSq8kSZK03aYa8N4+zE5IkiRp5kz1a1IuSfJ0YGlVfSXJE4Adhts1SZIkbY8pPYOX5A3Ap4EPtKa9gL8ZVqckSZK0/aY6yOIE4EXAfQBVdRPwc8PqlCRJkrbfVAPeg1X10PhMkkX0vwdPkiRJ88xUA94lSd4K7JTk5cCngM8Pr1uSJEnaXlMNeGuAHwDXAm8E1gJvG1anJEmStP2mOor2Z8AH20uSJEnz2FR/i/Z7TPDMXVU9Y8Z7JEmSpGl5NL9FO+7xwG8Du898dyRJkjRdU3oGr6ruGnhtrKo/A44cct8kSZK0HaZ6i/bAgdnH0L+iN9Wrf5IkSZpFUw1p7x6Y3gysB14z472RJEnStE11FO1vDLsjkiRJmhlTvUX7h1tbXlXvmZnuSJIkaboezSjaFwLnt/lXAJcDNw2jU5IkSdp+Uw14ewMHVtX9AEneDlxQVb87rI5JkiRp+0z1p8oWAw8NzD/U2iRJkjTPTPUK3tnA5UnOa/NHAWcNp0uSJEmajqmOoj0lyReBX2tNr6+qbw2vW5IkSdpeU71FC/AE4L6q+nNgQ5J9h9QnSZIkTcOUAl6Sk4A3A29pTY8F/npYnZIkSdL2m+oVvFcBrwR+DFBV3weetLUNkpyZ5M4k3xloe3uSjUmubq8jBpa9Jcm6JDcmOWygfXlrW5dkzUD7vkkua+2fTLLjFM9FkiSp06Ya8B6qqgIKIMnOU9jmI8DyCdpPq6oD2mtt299+wNHAc9s270uyQ5IdgPcChwP7Aa9t6wK8q+3rWcA9wPFTPBdJkqROm2rAOzfJB4Bdk7wB+Arwwa1tUFVfA+6e4v5XAOdU1YNV9T1gHXBQe62rqpur6iHgHGBFkgAvBT7dtj+L/sheSZKkBW+bo2hbmPok8BzgPuDZwH+rqou285gnJjkWuBJYXVX3AHsBlw6ss6G1Ady6RfvBwFOAe6tq8wTrT3QOq4BVAIsXL6bX621n17du06ZN9Ho9Vu+/edsrj4hhvVdzbbxWmt+s0+iwVqPBOo2O6dZqmwGvqirJ2qraH9jeUDfu/cDJ9G/1ngy8G/i9ae5zm6rqDOAMgGXLltXY2NhQjtPr9RgbG+O4NRcMZf9zYf0xY3PdhaEYr5XmN+s0OqzVaLBOo2O6tZrqLdpvJnnhdh+lqao7qurhqvoZ/Vu8B7VFG4F9Blbdu7VN1n4X/dvFi7ZolyRJWvCmGvAOBi5N8t0k1yS5Nsk1j/ZgSfYcmH0VMD7C9nzg6CSPa9+vtxS4HLgCWNpGzO5IfyDG+W3Ax1eBV7ftVwKfe7T9kSRJ6qKt3qJN8gtV9Y/AYVtbb5JtPwGMAXsk2QCcBIwlOYD+Ldr1wBsBquq6JOcC1wObgROq6uG2nxOBC4EdgDOr6rp2iDcD5yR5J/At4EOPto+SJEldtK1n8P4GOLCqbknymar6ranuuKpeO0HzpCGsqk4BTpmgfS2wdoL2m/mXW7ySJElqtnWLNgPTzxhmRyRJkjQzthXwapJpSZIkzVPbukX7vCT30b+St1Obps1XVe0y1N5JkiTpUdtqwKuqHWarI5IkSZoZU/2aFEmSJI0IA54kSVLHGPAkSZI6xoAnSZLUMQY8SZKkjjHgSZIkdYwBT5IkqWMMeJIkSR1jwJMkSeoYA54kSVLHGPAkSZI6xoAnSZLUMQY8SZKkjjHgSZIkdYwBT5IkqWMMeJIkSR1jwJMkSeoYA54kSVLHGPAkSZI6xoAnSZLUMQY8SZKkjjHgSZIkdYwBT5IkqWMMeJIkSR1jwJMkSeoYA54kSVLHGPAkSZI6xoAnSZLUMQY8SZKkjjHgSZIkdYwBT5IkqWMMeJIkSR1jwJMkSeoYA54kSVLHGPAkSZI6ZmgBL8mZSe5M8p2Btt2TXJTkpvZ3t9aeJKcnWZfkmiQHDmyzsq1/U5KVA+0vSHJt2+b0JBnWuUiSJI2SYV7B+wiwfIu2NcDFVbUUuLjNAxwOLG2vVcD7oR8IgZOAg4GDgJPGQ2Fb5w0D2215LEmSpAVpaAGvqr4G3L1F8wrgrDZ9FnDUQPvZ1XcpsGuSPYHDgIuq6u6quge4CFjelu1SVZdWVQFnD+xLkiRpQVs0y8dbXFW3tenbgcVtei/g1oH1NrS2rbVvmKB9QklW0b8yyOLFi+n1ett/BluxadMmer0eq/ffPJT9z4VhvVdzbbxWmt+s0+iwVqPBOo2O6dZqtgPeP6uqSlKzdKwzgDMAli1bVmNjY0M5Tq/XY2xsjOPWXDCU/c+F9ceMzXUXhmK8VprfrNPosFajwTqNjunWarZH0d7Rbq/S/t7Z2jcC+wyst3dr21r73hO0S5IkLXizHfDOB8ZHwq4EPjfQfmwbTXsI8KN2K/dC4NAku7XBFYcCF7Zl9yU5pI2ePXZgX5IkSQva0G7RJvkEMAbskWQD/dGwpwLnJjkeuAV4TVt9LXAEsA54AHg9QFXdneRk4Iq23juqanzgxu/TH6m7E/DF9pIkSVrwhhbwquq1kyx62QTrFnDCJPs5EzhzgvYrgV+eTh8lSZK6yF+ykCRJ6hgDniRJUscY8CRJkjrGgCdJktQxBjxJkqSOMeBJkiR1jAFPkiSpYwx4kiRJHWPAkyRJ6hgDniRJUscY8CRJkjrGgCdJktQxBjxJkqSOMeBJkiR1jAFPkiSpYwx4kiRJHWPAkyRJ6hgDniRJUscY8CRJkjrGgCdJktQxBjxJkqSOWTTXHdD8tmTNBUM/xvpTjxz6MSRJWki8gidJktQxBjxJkqSOMeBJkiR1jAFPkiSpYwx4kiRJHWPAkyRJ6hgDniRJUscY8CRJkjrGgCdJktQxBjxJkqSOMeBJkiR1jAFPkiSpYwx4kiRJHWPAkyRJ6hgDniRJUscY8CRJkjrGgCdJktQxcxLwkqxPcm2Sq5Nc2dp2T3JRkpva391ae5KcnmRdkmuSHDiwn5Vt/ZuSrJyLc5EkSZpv5vIK3m9U1QFVtazNrwEurqqlwMVtHuBwYGl7rQLeD/1ACJwEHAwcBJw0HgolSZIWsvl0i3YFcFabPgs4aqD97Oq7FNg1yZ7AYcBFVXV3Vd0DXAQsn+1OS5IkzTdzFfAK+HKSq5Ksam2Lq+q2Nn07sLhN7wXcOrDthtY2WbskSdKCtmiOjvviqtqY5OeAi5L8w+DCqqokNVMHayFyFcDixYvp9XoztetH2LRpE71ej9X7bx7K/rtqWPXYmvFaaX6zTqPDWo0G6zQ6plurOQl4VbWx/b0zyXn0n6G7I8meVXVbuwV7Z1t9I7DPwOZ7t7aNwNgW7b1JjncGcAbAsmXLamxsbKLVpq3X6zE2NsZxay4Yyv67av0xY7N+zPFaaX6zTqPDWo0G6zQ6plurWb9Fm2TnJE8anwYOBb4DnA+Mj4RdCXyuTZ8PHNtG0x4C/Kjdyr0QODTJbm1wxaGtTZIkaUGbiyt4i4Hzkowf/+NV9aUkVwDnJjkeuAV4TVt/LXAEsA54AHg9QFXdneRk4Iq23juq6u7ZOw1JkqT5adYDXlXdDDxvgva7gJdN0F7ACZPs60zgzJnuoyRJ0iibT1+TIkmSpBlgwJMkSeoYA54kSVLHGPAkSZI6xoAnSZLUMQY8SZKkjjHgSZIkdYwBT5IkqWMMeJIkSR1jwJMkSeoYA54kSVLHGPAkSZI6ZtFcd0BasuaCWTnO+lOPnJXjSJI017yCJ0mS1DEGPEmSpI4x4EmSJHWMAU+SJKljDHiSJEkdY8CTJEnqGAOeJElSxxjwJEmSOsaAJ0mS1DEGPEmSpI4x4EmSJHWMAU+SJKljDHiSJEkdY8CTJEnqmEVz3QFptixZc8E/T6/efzPHDczPlPWnHjnj+5Qk6dHyCp4kSVLHGPAkSZI6xoAnSZLUMQY8SZKkjjHgSZIkdYyjaKUZtGQII3O35EhdSdK2eAVPkiSpYwx4kiRJHeMtWmnEzMZtYPBWsCSNMq/gSZIkdYxX8CRNyAEjkjS6Rj7gJVkO/DmwA/BXVXXqHHdJ0hRtK0TOxG8GGyIlLUQjHfCS7AC8F3g5sAG4Isn5VXX93PZM0nzhM4uSFqKRDnjAQcC6qroZIMk5wArAgCdpVs1WkJyvHu3VVgOxNFyjHvD2Am4dmN8AHDxHfZEkTZHPeErDNeoBb0qSrAJWtdlNSW4c0qH2AH44pH1rBv1nazUSrNPomI+1yrvmugfz0ryrkyY1Xqunb8/Gox7wNgL7DMzv3doeoarOAM4YdmeSXFlVy4Z9HE2ftRoN1ml0WKvRYJ1Gx3RrNerfg3cFsDTJvkl2BI4Gzp/jPkmSJM2pkb6CV1Wbk5wIXEj/a1LOrKrr5rhbkiRJc2qkAx5AVa0F1s51P5qh3wbWjLFWo8E6jQ5rNRqs0+iYVq1SVTPVEUmSJM0Do/4MniRJkrZgwJsBSZYnuTHJuiRr5ro/eqQk65Ncm+TqJFe2tt2TXJTkpvZ3t7nu50KU5Mwkdyb5zkDbhLVJ3+ntc3ZNkgPnrucLyyR1enuSje1zdXWSIwaWvaXV6cYkh81NrxemJPsk+WqS65Ncl+QPWrufq3lkK3WasUU74J0AAAK9SURBVM+VAW+aBn4u7XBgP+C1Sfab215pAr9RVQcMDDlfA1xcVUuBi9u8Zt9HgOVbtE1Wm8OBpe21Cnj/LPVRE9cJ4LT2uTqgPQ9N+/fvaOC5bZv3tX8nNTs2A6uraj/gEOCEVhM/V/PLZHWCGfpcGfCm759/Lq2qHgLGfy5N89sK4Kw2fRZw1Bz2ZcGqqq8Bd2/RPFltVgBnV9+lwK5J9pydni5sk9RpMiuAc6rqwar6HrCO/r+TmgVVdVtVfbNN3w/cQP9Xn/xczSNbqdNkHvXnyoA3fRP9XNrWiqTZV8CXk1zVftUEYHFV3dambwcWz03XNIHJauNnbf45sd3WO3PgMQfrNE8kWQI8H7gMP1fz1hZ1ghn6XBnwtBC8uKoOpH8r4oQkvz64sPpDyR1OPg9Zm3nt/cAzgQOA24B3z213NCjJE4HPAG+qqvsGl/m5mj8mqNOMfa4MeNM3pZ9L09ypqo3t753AefQva98xfhui/b1z7nqoLUxWGz9r80hV3VFVD1fVz4AP8i+3i6zTHEvyWPqh4WNV9dnW7OdqnpmoTjP5uTLgTZ8/lzaPJdk5yZPGp4FDge/Qr9HKttpK4HNz00NNYLLanA8c20b9HQL8aOCWk2bZFs9pvYr+5wr6dTo6yeOS7Ev/4f3LZ7t/C1WSAB8Cbqiq9wws8nM1j0xWp5n8XI38L1nMNX8ubd5bDJzX/yyxCPh4VX0pyRXAuUmOB24BXjOHfVywknwCGAP2SLIBOAk4lYlrsxY4gv7DxQ8Ar5/1Di9Qk9RpLMkB9G/1rQfeCFBV1yU5F7ie/kjBE6rq4bno9wL1IuB1wLVJrm5tb8XP1XwzWZ1eO1OfK3/JQpIkqWO8RStJktQxBjxJkqSOMeBJkiR1jAFPkiSpYwx4kiRJHWPAkyRJ6hgDniRJUscY8CRJkjrm/wO1n/aMQWC/6QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pFWV_a-mUZl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOEF4DScUDPi"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_checkpoint = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrWBwldIWmjJ"
      },
      "source": [
        "import transformers\n",
        "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCdTbs69Wxbh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d14c31c-e75d-4cd7-e6a4-de56174d4d97"
      },
      "source": [
        "tokenizer(\"What is your name?\", \"My name is Sylvain.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 2054, 2003, 2115, 2171, 1029, 102, 2026, 2171, 2003, 25353, 22144, 2378, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhmVAsCrXKD9"
      },
      "source": [
        "max_length = 384 # The maximum length of a feature (question and context)\n",
        "doc_stride = 128 # The authorized overlap between two part of the context when splitting it is needed."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3ddtDfBX4k7"
      },
      "source": [
        "tokenized_example = tokenizer(\n",
        "    example[\"question\"],\n",
        "    example[\"context\"],\n",
        "    max_length=max_length,\n",
        "    truncation=\"only_second\",\n",
        "    return_overflowing_tokens=True,\n",
        "    stride=doc_stride\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JWjzfhBOVApq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MspPpyCyalUB"
      },
      "source": [
        "def prepare_train_features(examples: collections.OrderedDict or dict) -> transformers.tokenization_utils_base.BatchEncoding:\n",
        "    \"\"\"Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n",
        "        in one example possible giving several features when a context is long, each of those features having a\n",
        "        context that overlaps a bit the context of the previous feature.\n",
        "\n",
        "      Args:\n",
        "        examples: Squad samples\n",
        "    \"\"\"\n",
        "    tokenized_examples = tokenizer(\n",
        "        examples[\"question\" if pad_on_right else \"context\"],\n",
        "        examples[\"context\" if pad_on_right else \"question\"],\n",
        "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
        "        max_length=max_length,\n",
        "        stride=doc_stride,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
        "    # its corresponding example. This key gives us just that.\n",
        "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
        "    # The offset mappings will give us a map from token to character position in the original context. This will\n",
        "    # help us compute the start_positions and end_positions.\n",
        "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
        "\n",
        "    # Let's label those examples!\n",
        "    tokenized_examples[\"start_positions\"] = []\n",
        "    tokenized_examples[\"end_positions\"] = []\n",
        "\n",
        "    for i, offsets in enumerate(offset_mapping):\n",
        "        # CLS index\n",
        "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
        "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
        "\n",
        "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "\n",
        "        # One example can give several spans, this is the index of the example containing this span of text.\n",
        "        sample_index = sample_mapping[i]\n",
        "        answers = examples[\"answers\"][sample_index]\n",
        "\n",
        "        # Start/end character index of the answer in the text.\n",
        "        start_char = answers[\"answer_start\"][0]\n",
        "        end_char = start_char + len(answers[\"text\"][0])\n",
        "\n",
        "        # Start token index of the current span in the text.\n",
        "        token_start_index = 0\n",
        "        while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
        "            token_start_index += 1\n",
        "\n",
        "        # End token index of the current span in the text.\n",
        "        token_end_index = len(input_ids) - 1\n",
        "        while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
        "            token_end_index -= 1\n",
        "\n",
        "        # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
        "        if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
        "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "        else:\n",
        "            # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n",
        "            # Note: we could go after the last offset if the answer is the last word (edge case).\n",
        "            while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
        "                token_start_index += 1\n",
        "            tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
        "            while offsets[token_end_index][1] >= end_char:\n",
        "                token_end_index -= 1\n",
        "            tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
        "\n",
        "    return tokenized_examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_ByXJPbcwNG"
      },
      "source": [
        "features = prepare_train_features(train_data['train'][:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tokenized_datasets = train_data.map(prepare_train_features, batched=True, remove_columns=train_data['train'].column_names)"
      ],
      "metadata": {
        "id": "jSzGQSGtVfby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV0pZMjOPly2"
      },
      "source": [
        "# DistilBert\n",
        "\n",
        "import math\n",
        "\n",
        "from transformers.modeling_outputs import QuestionAnsweringModelOutput\n",
        "from transformers import DistilBertPreTrainedModel\n",
        "from transformers import DistilBertModel\n",
        "\n",
        "from torch import nn\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "\n",
        "def gelu(x):\n",
        "    \"\"\"\n",
        "    Original Implementation of the GELU activation function in Google BERT repo when initially created. For\n",
        "    information: OpenAI GPT's GELU is slightly different (and gives slightly different results): 0.5 * x * (1 +\n",
        "    torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3)))) This is now written in C in\n",
        "    torch.nn.functional Also see the Gaussian Error Linear Units paper: https://arxiv.org/abs/1606.08415\n",
        "    \"\"\"\n",
        "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n",
        "\n",
        "\n",
        "def gelu_new(x):\n",
        "    \"\"\"\n",
        "    Implementation of the GELU activation function currently in Google BERT repo (identical to OpenAI GPT). Also see\n",
        "    the Gaussian Error Linear Units paper: https://arxiv.org/abs/1606.08415\n",
        "    \"\"\"\n",
        "    return 0.5 * x * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * torch.pow(x, 3.0))))\n",
        "\n",
        "\n",
        "class DistilBertForQuestionAnswering(DistilBertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        self.distilbert = DistilBertModel(config)\n",
        "\n",
        "        self.qa_outputs_0 = nn.Linear(config.dim, 512)\n",
        "        self.qa_outputs_1 = nn.Linear(512, 32)\n",
        "        self.qa_outputs = nn.Linear(32, config.num_labels)\n",
        "\n",
        "        assert config.num_labels == 2\n",
        "        self.dropout = nn.Dropout(config.qa_dropout)\n",
        "\n",
        "        self.LayerNorm = nn.LayerNorm(normalized_shape = [384,2])\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        start_positions=None,\n",
        "        end_positions=None,\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=None,\n",
        "        return_dict=None,\n",
        "    ):\n",
        "        r\"\"\"\n",
        "        start_positions (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n",
        "            Labels for position (index) of the start of the labelled span for computing the token classification loss.\n",
        "            Positions are clamped to the length of the sequence (:obj:`sequence_length`). Position outside of the\n",
        "            sequence are not taken into account for computing the loss.\n",
        "        end_positions (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n",
        "            Labels for position (index) of the end of the labelled span for computing the token classification loss.\n",
        "            Positions are clamped to the length of the sequence (:obj:`sequence_length`). Position outside of the\n",
        "            sequence are not taken into account for computing the loss.\n",
        "        \"\"\"\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "\n",
        "        distilbert_output = self.distilbert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "\n",
        "        hidden_states = distilbert_output[0]  # (bs, max_query_len, dim)\n",
        "        hidden_states = self.dropout(hidden_states)  # (bs, max_query_len, dim)\n",
        "\n",
        "        logits = gelu_new(self.qa_outputs_0(hidden_states))  # (bs, max_query_len, 2)\n",
        "        logits = gelu_new(self.qa_outputs_1(logits))\n",
        "        #logits = self.LayerNorm_0(logits)\n",
        "\n",
        "        logits = self.qa_outputs(logits)\n",
        "        logits = self.LayerNorm(logits)\n",
        "\n",
        "        start_logits, end_logits = logits.split(1, dim=-1)\n",
        "\n",
        "        start_logits = start_logits.squeeze(-1)  # (bs, max_query_len)\n",
        "        end_logits = end_logits.squeeze(-1)  # (bs, max_query_len)\n",
        "\n",
        "\n",
        "        total_loss = None\n",
        "        if start_positions is not None and end_positions is not None:\n",
        "\n",
        "            # sometimes the start/end positions are outside our model inputs, we ignore these terms\n",
        "            ignored_index = start_logits.size(1)\n",
        "            start_positions.clamp_(0, ignored_index)\n",
        "            end_positions.clamp_(0, ignored_index)\n",
        "\n",
        "            loss_fct = nn.CrossEntropyLoss(ignore_index=ignored_index)\n",
        "            start_loss = loss_fct(start_logits, start_positions)\n",
        "            end_loss = loss_fct(end_logits, end_positions)\n",
        "            total_loss = (start_loss + end_loss) / 2\n",
        "\n",
        "        if not return_dict:\n",
        "          output = (start_logits, end_logits) + distilbert_output[1:]\n",
        "          return ((total_loss,) + output) if total_loss is not None else output\n",
        "\n",
        "        return QuestionAnsweringModelOutput(\n",
        "            loss=total_loss,\n",
        "            start_logits=start_logits,\n",
        "            end_logits=end_logits,\n",
        "            hidden_states=distilbert_output.hidden_states,\n",
        "            attentions=distilbert_output.attentions\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVzYPE4Pd2tY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f3238f2-920f-459c-8971-d393028c3b9f"
      },
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "model = DistilBertForQuestionAnswering.from_pretrained(model_checkpoint)\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "if torch.cuda.is_available():\n",
        "  model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs_0.weight', 'qa_outputs_0.bias', 'qa_outputs_1.weight', 'qa_outputs_1.bias', 'qa_outputs.weight', 'qa_outputs.bias', 'LayerNorm.weight', 'LayerNorm.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PIiVlDYCtSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "161963be-83e2-480a-93b2-a3ac94b0e7bf"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The {} model has {:} different named parameters.\\n'.format(model_checkpoint,len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layers ====\\n')\n",
        "\n",
        "for p in params[-10:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The distilbert-base-uncased model has 108 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "distilbert.embeddings.word_embeddings.weight            (30522, 768)\n",
            "distilbert.embeddings.position_embeddings.weight          (512, 768)\n",
            "distilbert.embeddings.LayerNorm.weight                        (768,)\n",
            "distilbert.embeddings.LayerNorm.bias                          (768,)\n",
            "distilbert.transformer.layer.0.attention.q_lin.weight     (768, 768)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "distilbert.transformer.layer.0.attention.q_lin.bias           (768,)\n",
            "distilbert.transformer.layer.0.attention.k_lin.weight     (768, 768)\n",
            "distilbert.transformer.layer.0.attention.k_lin.bias           (768,)\n",
            "distilbert.transformer.layer.0.attention.v_lin.weight     (768, 768)\n",
            "distilbert.transformer.layer.0.attention.v_lin.bias           (768,)\n",
            "distilbert.transformer.layer.0.attention.out_lin.weight   (768, 768)\n",
            "distilbert.transformer.layer.0.attention.out_lin.bias         (768,)\n",
            "distilbert.transformer.layer.0.sa_layer_norm.weight           (768,)\n",
            "distilbert.transformer.layer.0.sa_layer_norm.bias             (768,)\n",
            "distilbert.transformer.layer.0.ffn.lin1.weight           (3072, 768)\n",
            "distilbert.transformer.layer.0.ffn.lin1.bias                 (3072,)\n",
            "distilbert.transformer.layer.0.ffn.lin2.weight           (768, 3072)\n",
            "distilbert.transformer.layer.0.ffn.lin2.bias                  (768,)\n",
            "distilbert.transformer.layer.0.output_layer_norm.weight       (768,)\n",
            "distilbert.transformer.layer.0.output_layer_norm.bias         (768,)\n",
            "distilbert.transformer.layer.1.attention.q_lin.weight     (768, 768)\n",
            "\n",
            "==== Output Layers ====\n",
            "\n",
            "distilbert.transformer.layer.5.output_layer_norm.weight       (768,)\n",
            "distilbert.transformer.layer.5.output_layer_norm.bias         (768,)\n",
            "qa_outputs_0.weight                                       (512, 768)\n",
            "qa_outputs_0.bias                                             (512,)\n",
            "qa_outputs_1.weight                                        (32, 512)\n",
            "qa_outputs_1.bias                                              (32,)\n",
            "qa_outputs.weight                                            (2, 32)\n",
            "qa_outputs.bias                                                 (2,)\n",
            "LayerNorm.weight                                            (384, 2)\n",
            "LayerNorm.bias                                              (384, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzRCzB0xeL0t"
      },
      "source": [
        "batch_size = 32\n",
        "args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    save_total_limit=5,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    label_names=[\"start_positions\", \"end_positions\"]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0C4Gxg0emtD"
      },
      "source": [
        "from transformers import default_data_collator\n",
        "\n",
        "data_collator = default_data_collator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FlROrJIi9Th"
      },
      "source": [
        "import collections\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "\n",
        "\n",
        "def postprocess_qa_predictions(examples: datasets.arrow_dataset.Dataset,\n",
        "                               features: datasets.arrow_dataset.Dataset,\n",
        "                               raw_predictions: tuple,\n",
        "                               n_best_size: int = 20,\n",
        "                               max_answer_length: int = 50) -> collections.OrderedDict:\n",
        "    \"\"\"Function used to select the best answer from the raw predictions\n",
        "\n",
        "      Args:\n",
        "        examples: Squad samples\n",
        "        features: Squad features\n",
        "        raw_predictions: model predictions\n",
        "    \"\"\"\n",
        "    all_start_logits, all_end_logits = raw_predictions\n",
        "    # Build a map example to its corresponding features.\n",
        "    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
        "    features_per_example = collections.defaultdict(list)\n",
        "    for i, feature in enumerate(features):\n",
        "        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
        "\n",
        "    # The dictionaries we have to fill.\n",
        "    predictions = collections.OrderedDict()\n",
        "\n",
        "    # Let's loop over all the examples!\n",
        "    for example_index, example in enumerate(tqdm(examples)):\n",
        "        # Those are the indices of the features associated to the current example.\n",
        "        feature_indices = features_per_example[example_index]\n",
        "        valid_answers = []\n",
        "\n",
        "        context = example[\"context\"]\n",
        "        # Looping through all the features associated to the current example.\n",
        "        for feature_index in feature_indices:\n",
        "            # We grab the predictions of the model for this feature.\n",
        "            start_logits = all_start_logits[feature_index]\n",
        "            end_logits = all_end_logits[feature_index]\n",
        "            # This is what will allow us to map some the positions in our logits to span of texts in the original\n",
        "            # context.\n",
        "            offset_mapping = features[feature_index][\"offset_mapping\"]\n",
        "\n",
        "            # Update minimum null prediction.\n",
        "            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n",
        "            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
        "\n",
        "            # Go through all possibilities for the `n_best_size` greater start and end logits.\n",
        "            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "            for start_index in start_indexes:\n",
        "                for end_index in end_indexes:\n",
        "                    # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
        "                    # to part of the input_ids that are not in the context.\n",
        "                    if (\n",
        "                        start_index >= len(offset_mapping)\n",
        "                        or end_index >= len(offset_mapping)\n",
        "                        or offset_mapping[start_index] is None\n",
        "                        or offset_mapping[end_index] is None\n",
        "                    ):\n",
        "                        continue\n",
        "                    # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
        "                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
        "                        continue\n",
        "\n",
        "                    start_char = offset_mapping[start_index][0]\n",
        "                    end_char = offset_mapping[end_index][1]\n",
        "                    valid_answers.append(\n",
        "                        {\n",
        "                            \"score\": start_logits[start_index] + end_logits[end_index],\n",
        "                            \"text\": context[start_char: end_char]\n",
        "                        }\n",
        "                    )\n",
        "\n",
        "        if len(valid_answers) > 0:\n",
        "            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
        "        else:\n",
        "            # In the very rare edge case we have not a single non-null prediction, we create a fake prediction to avoid\n",
        "            # failure.\n",
        "            best_answer = {\"text\": \"\", \"score\": 0.0}\n",
        "\n",
        "        # Let's pick our final answer\n",
        "        predictions[example[\"id\"]] = best_answer[\"text\"]\n",
        "\n",
        "    return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZoJcV9_hmqq"
      },
      "source": [
        "def prepare_validation_features(examples: collections.OrderedDict or dict) -> transformers.tokenization_utils_base.BatchEncoding:\n",
        "    \"\"\"To check a given span is inside the context (and not the question) and to get back the text inside.\n",
        "        To do this, we need to add two things to our validation features:\n",
        "        - the ID of the example that generated the feature (since each example can generate several features, as seen before);\n",
        "        - the offset mapping that will give us a map from token indices to character positions in the context.\n",
        "        That's why we will re-process the validation set with the following function, slightly different from `prepare_train_features`\n",
        "\n",
        "      Args:\n",
        "        examples: Squad samples\n",
        "    \"\"\"\n",
        "    # Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results\n",
        "    # in one example possible giving several features when a context is long, each of those features having a\n",
        "    # context that overlaps a bit the context of the previous feature.\n",
        "    tokenized_examples = tokenizer(\n",
        "        examples[\"question\" if pad_on_right else \"context\"],\n",
        "        examples[\"context\" if pad_on_right else \"question\"],\n",
        "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
        "        max_length=max_length,\n",
        "        stride=doc_stride,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
        "    # its corresponding example. This key gives us just that.\n",
        "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
        "\n",
        "    # The offset mappings will give us a map from token to character position in the original context. This will\n",
        "    # help us compute the start_positions and end_positions.\n",
        "    offset_mapping = tokenized_examples[\"offset_mapping\"]\n",
        "\n",
        "    # Let's label those examples!\n",
        "    tokenized_examples[\"start_positions\"] = []\n",
        "    tokenized_examples[\"end_positions\"] = []\n",
        "\n",
        "    for i, offsets in enumerate(offset_mapping):\n",
        "      # CLS index\n",
        "      input_ids = tokenized_examples[\"input_ids\"][i]\n",
        "      cls_index = input_ids.index(tokenizer.cls_token_id)\n",
        "\n",
        "      # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
        "      sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "\n",
        "      # One example can give several spans, this is the index of the example containing this span of text.\n",
        "      sample_index = sample_mapping[i]\n",
        "      answers = examples[\"answers\"][sample_index]\n",
        "\n",
        "      # Start/end character index of the answer in the text.\n",
        "      start_char = answers[\"answer_start\"][0]\n",
        "      end_char = start_char + len(answers[\"text\"][0])\n",
        "\n",
        "      # Start token index of the current span in the text.\n",
        "      token_start_index = 0\n",
        "      while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
        "          token_start_index += 1\n",
        "\n",
        "      # End token index of the current span in the text.\n",
        "      token_end_index = len(input_ids) - 1\n",
        "      while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
        "          token_end_index -= 1\n",
        "\n",
        "      # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
        "      if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
        "          tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "          tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "      else:\n",
        "          # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n",
        "          # Note: we could go after the last offset if the answer is the last word (edge case).\n",
        "          while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
        "              token_start_index += 1\n",
        "          tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
        "          while offsets[token_end_index][1] >= end_char:\n",
        "              token_end_index -= 1\n",
        "          tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
        "\n",
        "    # We keep the example_id that gave us this feature and we will store the offset mappings.\n",
        "    tokenized_examples[\"example_id\"] = []\n",
        "\n",
        "    for i in range(len(tokenized_examples[\"input_ids\"])):\n",
        "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "        context_index = 1 if pad_on_right else 0\n",
        "\n",
        "        # One example can give several spans, this is the index of the example containing this span of text.\n",
        "        sample_index = sample_mapping[i]\n",
        "        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
        "\n",
        "        # Set to None the offset_mapping that are not part of the context so it's easy to determine if a token\n",
        "        # position is part of the context or not.\n",
        "        tokenized_examples[\"offset_mapping\"][i] = [\n",
        "            (o if sequence_ids[k] == context_index else None)\n",
        "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
        "        ]\n",
        "\n",
        "    return tokenized_examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_features = val_data['train'].map(prepare_validation_features, batched=True, remove_columns=val_data['train'].column_names)"
      ],
      "metadata": {
        "id": "juJa5meqVtQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric = datasets.load_metric(\"squad\")"
      ],
      "metadata": {
        "id": "vpWtej_-Vvbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7NM_VjsTFr7"
      },
      "source": [
        "def compute_metrics(pred: transformers.trainer_utils.EvalPrediction) -> dict:\n",
        "    # The Trainer hides the columns that are not used by the model (here example_id and offset_mapping which we will need for our post-processing), so we set them back\n",
        "    validation_features.set_format(type=validation_features.format[\"type\"], columns=list(validation_features.features.keys()))\n",
        "\n",
        "    # To get the final predictions we can apply our post-processing function to our raw predictions\n",
        "    final_predictions = postprocess_qa_predictions(val_data['train'], validation_features, pred.predictions)\n",
        "\n",
        "    # We just need to format predictions and labels a bit as metric expects a list of dictionaries and not one big dictionary\n",
        "    formatted_predictions = [{\"id\": k, \"prediction_text\": v} for k, v in final_predictions.items()]\n",
        "    references = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in val_data[\"train\"]]\n",
        "\n",
        "    # Hide again the columns that are not used by the model\n",
        "    validation_features.set_format(type=validation_features.format[\"type\"], columns=['attention_mask', 'end_positions', 'input_ids', 'start_positions'])\n",
        "    metrics = metric.compute(predictions=formatted_predictions, references=references)\n",
        "\n",
        "    return metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaQeOtSNewJj"
      },
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_tokenized_datasets[\"train\"],\n",
        "    eval_dataset=validation_features,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "TojxJwVTV1pT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mi131NHMfYMt"
      },
      "source": [
        "trainer.save_model(data_path + \"test-squad-trained\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}